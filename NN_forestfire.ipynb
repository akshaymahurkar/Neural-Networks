{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data\n",
    "forestfires = pd.read_csv(\"C:/Users/shruti pandey/Downloads/forestfires.csv\")\n",
    "forestfires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "forestfires.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forestfires.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count of duplicated rows\n",
    "forestfires[forestfires.duplicated()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>92.1</td>\n",
       "      <td>111.2</td>\n",
       "      <td>654.1</td>\n",
       "      <td>9.6</td>\n",
       "      <td>20.4</td>\n",
       "      <td>42</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>91.4</td>\n",
       "      <td>142.4</td>\n",
       "      <td>601.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>39</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>mar</td>\n",
       "      <td>sat</td>\n",
       "      <td>91.7</td>\n",
       "      <td>35.8</td>\n",
       "      <td>80.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.1</td>\n",
       "      <td>94.1</td>\n",
       "      <td>232.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>38</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>aug</td>\n",
       "      <td>thu</td>\n",
       "      <td>91.6</td>\n",
       "      <td>248.4</td>\n",
       "      <td>753.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>20.4</td>\n",
       "      <td>56</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>93.7</td>\n",
       "      <td>231.1</td>\n",
       "      <td>715.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>18.9</td>\n",
       "      <td>64</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>96.1</td>\n",
       "      <td>181.1</td>\n",
       "      <td>671.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>21.6</td>\n",
       "      <td>65</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.0</td>\n",
       "      <td>166.9</td>\n",
       "      <td>752.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>41</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "53    aug  wed  92.1  111.2  654.1   9.6  20.4  42   4.9   0.0  ...         0   \n",
       "100   aug  sun  91.4  142.4  601.4  10.6  19.8  39   5.4   0.0  ...         0   \n",
       "215   mar  sat  91.7   35.8   80.8   7.8  17.0  27   4.9   0.0  ...         0   \n",
       "303   jun  fri  91.1   94.1  232.1   7.1  19.2  38   4.5   0.0  ...         0   \n",
       "426   aug  thu  91.6  248.4  753.8   6.3  20.4  56   2.2   0.0  ...         0   \n",
       "461   aug  sat  93.7  231.1  715.1   8.4  18.9  64   4.9   0.0  ...         0   \n",
       "501   aug  tue  96.1  181.1  671.2  14.3  21.6  65   4.9   0.8  ...         0   \n",
       "508   aug  fri  91.0  166.9  752.6   7.1  25.9  41   3.6   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "53          0         0         0         0         0         0         0   \n",
       "100         0         0         0         0         0         0         0   \n",
       "215         0         0         0         1         0         0         0   \n",
       "303         0         0         1         0         0         0         0   \n",
       "426         0         0         0         0         0         0         0   \n",
       "461         0         0         0         0         0         0         0   \n",
       "501         0         0         0         0         0         0         0   \n",
       "508         0         0         0         0         0         0         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "53          0          small  \n",
       "100         0          small  \n",
       "215         0          large  \n",
       "303         0          small  \n",
       "426         0          small  \n",
       "461         0          small  \n",
       "501         0          small  \n",
       "508         0          small  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the duplicated rows\n",
    "forestfires[forestfires.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[509 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping the Duplicates.\n",
    "forestfires.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month             object\n",
       "day               object\n",
       "FFMC             float64\n",
       "DMC              float64\n",
       "DC               float64\n",
       "ISI              float64\n",
       "temp             float64\n",
       "RH                 int64\n",
       "wind             float64\n",
       "rain             float64\n",
       "area             float64\n",
       "dayfri             int64\n",
       "daymon             int64\n",
       "daysat             int64\n",
       "daysun             int64\n",
       "daythu             int64\n",
       "daytue             int64\n",
       "daywed             int64\n",
       "monthapr           int64\n",
       "monthaug           int64\n",
       "monthdec           int64\n",
       "monthfeb           int64\n",
       "monthjan           int64\n",
       "monthjul           int64\n",
       "monthjun           int64\n",
       "monthmar           int64\n",
       "monthmay           int64\n",
       "monthnov           int64\n",
       "monthoct           int64\n",
       "monthsep           int64\n",
       "size_category     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data types\n",
    "forestfires.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As dummy variables are already created, we will remove the month and alsoday columns\n",
    "forestfires.drop([\"month\",\"day\"],axis=1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small    378\n",
       "large    139\n",
       "Name: size_category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forestfires[\"size_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing values\n",
    "forestfires.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    378\n",
       "1    139\n",
       "Name: size_category, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##I am taking small as 0 and large as 1\n",
    "forestfires.loc[forestfires[\"size_category\"]=='small','size_category']=0\n",
    "forestfires.loc[forestfires[\"size_category\"]=='large','size_category']=1\n",
    "forestfires[\"size_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization.\n",
    "def norm_func(i):\n",
    "     x = (i-i.min())/(i.max()-i.min())\n",
    "     return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "predictors = forestfires.iloc[:,0:28]\n",
    "target = forestfires.iloc[:,28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthdec  monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  \\\n",
       "0           0         0         0         0         0         1         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         1         0   \n",
       "4           0         0         0         0         0         1         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         0   \n",
       "\n",
       "     monthnov  monthoct  monthsep  \n",
       "0           0         0         0  \n",
       "1           0         1         0  \n",
       "2           0         1         0  \n",
       "3           0         0         0  \n",
       "4           0         0         0  \n",
       "..        ...       ...       ...  \n",
       "512         0         0         0  \n",
       "513         0         0         0  \n",
       "514         0         0         0  \n",
       "515         0         0         0  \n",
       "516         1         0         0  \n",
       "\n",
       "[517 rows x 28 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "512    1\n",
       "513    1\n",
       "514    1\n",
       "515    0\n",
       "516    0\n",
       "Name: size_category, Length: 517, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the predictor to normalizaition\n",
    "predictors1 = norm_func(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data using train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test= train_test_split(predictors1,target, test_size=0.3,stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the model\n",
    "def prep_model(hidden_dim):\n",
    "    model = Sequential()\n",
    "    for i in range(1,len(hidden_dim)-1):\n",
    "        if (i==1):\n",
    "            model.add(Dense(hidden_dim[i],input_dim=hidden_dim[0],activation=\"relu\"))\n",
    "        else:\n",
    "            model.add(Dense(hidden_dim[i],activation=\"relu\"))\n",
    "    model.add(Dense(hidden_dim[-1],kernel_initializer=\"normal\",activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer = \"rmsprop\",metrics = [\"accuracy\"])\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 1s 3ms/step - loss: 0.6871 - accuracy: 0.6106\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.7157\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.7153\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.7280\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6990\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7245\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7366\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7192\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5892 - accuracy: 0.7060\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7088\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7645\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.7765\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7082\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7232\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7348\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.7114\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5607 - accuracy: 0.7222\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5722 - accuracy: 0.7157\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5407 - accuracy: 0.7490\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7694\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7313\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7502\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7351\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7405\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.7528\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7605\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7219\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7284\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7374\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7211\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7290\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7585\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7578\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.7136\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7668\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7497\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7522\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7754\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7666\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7141\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7417\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7372\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7448\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.7574\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.7513\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7726\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7522\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7707\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7661\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8106\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7445\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7421\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7527\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7725\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7644\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7719\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7510\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7694\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7512\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7717\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7509\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7597\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7645\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7829\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7719\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7753\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7549\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7785\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7717\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7679\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7815\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7724\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8037\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7578\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7782\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7904\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7493\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7920\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7545\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.7659\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7754\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7765\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7930\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7593\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7883\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.7426\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7767\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7612\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7630\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7743\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7711\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7881\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7564\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7841\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7933\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7762\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7919\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8046\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7673\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7807\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7783\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7352\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7952\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7551\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7418\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7861\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7710\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7862\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7890\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7691\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7797\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7996\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7744\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7896\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7776\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.7630\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7912\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7656\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7319\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7723\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7635\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7912\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7677\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7926\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7835\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8132\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7673\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7663\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.7358\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7640\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7456\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7719\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7490\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7718\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7665\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7827\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7593\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7727\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7554\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7623\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7425\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5135 - accuracy: 0.7312\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7848\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7485\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7655\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7825\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8061\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7648\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7844\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7574\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7855\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4193 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7841\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.7505\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7516\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7802\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7740\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7447\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7394\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7887\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7605\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7699\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7666\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7442\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7893\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7585\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7480\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7565\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7668\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7795\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7849\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7559\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7639\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7873\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.8136\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7661\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7816\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7774\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7531\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7825\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7577\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7613\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7398\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7411\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7787\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7753\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7663\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7600\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7655\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7898\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7742\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7441\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7696\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7634\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7807\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7655\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7877\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7734\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7758\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7853\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7920\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7770\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7786\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7865\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7841\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7651\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7893\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7709\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7673\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8063\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7857\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7582\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.7723\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7649\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7783\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.7903\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7682\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7854\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7802\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7729\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7827\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7734\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.7984\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7706\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7892\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7824\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7678\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7730\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7828\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7657\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7793\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7573\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7856\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7859\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7548\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7720\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7797\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7829\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7601\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7648\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7897\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7922\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7855\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7885\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7862\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7772\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7851\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7614\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7506\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7348\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7610\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7661\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7619\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7650\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.8114\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.7769\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7864\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7843\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7659\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7842\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7705\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.7936\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7518\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7999\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7993\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7771\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7744\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.7525\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 819us/step - loss: 0.4432 - accuracy: 0.8050\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7466\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8026\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7938\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7706\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7589\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7642\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7710\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7545\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7502\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 938us/step - loss: 0.4711 - accuracy: 0.7749\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7854\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7917\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7815\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7910\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7579\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7434\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7522\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7801\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7842\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7663\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7765\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7876\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7981\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7933\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7824\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7534\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7875\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7854\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7772\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7652\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7817\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7844\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7836\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8123\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7758\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 989us/step - loss: 0.4633 - accuracy: 0.7814\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7177\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.7644\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7836\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7721\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7495\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7706\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7882\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.7754\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7978\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7758\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7654\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7921\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7800\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7734\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7648\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7649\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7942\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7839\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7816\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.7926\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7862\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7913\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7764\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7671\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7552\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7769\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7582\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7912\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7304\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7691\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7847\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7754\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7408\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8289\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7564\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7773\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7803\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7669\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7805\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7996\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8023\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7788\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7631\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7667\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7901\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7723\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7281\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7749\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7908\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7602\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.7902\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7709\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7319\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7791\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7632\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7689\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7732\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7804\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7638\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7959\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7468\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7930\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7713\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7996\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7753\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7649\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7840\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7869\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7979\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7476\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7699\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7601\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7883\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7762\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7631\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7819\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7865\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7704\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7837\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7698\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7667\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7656\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7575\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7658\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7592\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7539\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7651\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7755\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7514\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7573\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7678\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7676\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7431\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7411\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7816\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8022\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4262 - accuracy: 0.7887\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7618\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8031\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7845\n",
      "Epoch 406/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7666\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7637\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7986\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7420\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7445\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7744\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7965\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7697\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7667\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7695\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7454\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7646\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7945\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7926\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7943\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7863\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7766\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7866\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7681\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7916\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7573\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7655\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7632\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7556\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7661\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7776\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8026\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7975\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7755\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7422\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7894\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7911\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7681\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7880\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7741\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7779\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7433\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7621\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7711\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7938\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7820\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7659\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7795\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7915\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7769\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7565\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7583\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7657\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7237\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7725\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7690\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8086\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7811\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7727\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8018\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7794\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7655\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7888\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7698\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7925\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7841\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7395\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7715\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7753\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 776us/step - loss: 0.4472 - accuracy: 0.7825\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7795\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7713\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7757\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7820\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7765\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7872\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7391\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7704\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7661\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7784\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7852\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7612\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.7551\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.7929\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.7722\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7724\n",
      "Epoch 487/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7653\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7637\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7868\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7389\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7929\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7444\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7673\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7741\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7641\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7431\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7531\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7982\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7727\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7751\n"
     ]
    }
   ],
   "source": [
    "#fitting the model to x train & y train\n",
    "first_model = prep_model([28,50,40,20,1])\n",
    "first_model.fit(np.asarray(x_train).astype(np.int),np.asarray(y_train).astype(np.int),epochs=500)\n",
    "pred_train = first_model.predict(np.array(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the predicted values to series \n",
    "pred_train = pd.Series([i[0] for i in pred_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = [\"small\",\"large\"]\n",
    "pred_train_class = pd.Series([\"small\"]*361)\n",
    "pred_train_class[[i>0.5 for i in pred_train]]= \"large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    264\n",
       "1     97\n",
       "Name: size_category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([x_train,y_train],axis=1)\n",
    "train[\"size_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7313019390581718"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For training data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "train[\"original_class\"] = \"small\"\n",
    "train.loc[train[\"size_category\"]==1,\"original_class\"] = \"large\"\n",
    "train.original_class.value_counts()\n",
    "confusion_matrix(pred_train_class,train[\"original_class\"])\n",
    "np.mean(pred_train_class==pd.Series(train[\"original_class\"]).reset_index(drop=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>original_class</th>\n",
       "      <th>large</th>\n",
       "      <th>small</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>small</th>\n",
       "      <td>97</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "original_class  large  small\n",
       "row_0                       \n",
       "small              97    264"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix for train data\n",
    "pd.crosstab(pred_train_class,pd.Series(train[\"original_class\"]).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For test data\n",
    "pred_test = first_model.predict(x_test)\n",
    "pred_test = pd.Series([i[0] for i in pred_test])\n",
    "pred_test_class = pd.Series([\"small\"]*156)\n",
    "pred_test_class[[i>0.5 for i in pred_test]] = \"large\"\n",
    "test =pd.concat([x_test,y_test],axis=1)\n",
    "test[\"original_class\"]=\"small\"\n",
    "test.loc[test[\"size_category\"]==1,\"original_class\"] = \"large\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7307692307692307"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"original_class\"].value_counts()\n",
    "np.mean(pred_test_class==pd.Series(test[\"original_class\"]).reset_index(drop=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>original_class</th>\n",
       "      <th>large</th>\n",
       "      <th>small</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>small</th>\n",
       "      <td>42</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "original_class  large  small\n",
       "row_0                       \n",
       "small              42    114"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix for test data\n",
    "confusion_matrix(pred_test_class,test[\"original_class\"])\n",
    "pd.crosstab(pred_test_class,pd.Series(test[\"original_class\"]).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Different models using diffrent loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m           \u001b[0mspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[1;34m(element, use_fallback)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m   raise TypeError(\"Could not build a TypeSpec for %r with type %s\" %\n\u001b[0m\u001b[0;32m    480\u001b[0m                   (element, type(element).__name__))\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not build a TypeSpec for 31     0\n450    1\n316    0\n363    0\n421    0\n      ..\n341    0\n41     0\n308    0\n314    0\n230    1\nName: size_category, Length: 156, dtype: object with type Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-bcf4bac7daee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfirst_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1427\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1430\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1346\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_data_adapter_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"batch\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[1;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[0;32m    347\u001b[0m     dataset = tf.data.Dataset.zip((\n\u001b[0;32m    348\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m     ))\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    679\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \"\"\"\n\u001b[1;32m--> 681\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   3299\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.from_tensors()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3301\u001b[1;33m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3302\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3303\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;31m# the value. As a fallback try converting the value to a tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         normalized_components.append(\n\u001b[1;32m--> 111\u001b[1;33m             ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[0;32m    112\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    337\u001b[0m                                          as_ref=False):\n\u001b[0;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m--> 264\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    265\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    274\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m   \u001b[1;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "scores = first_model.evaluate(x_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (first_model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the model\n",
    "def prep_model(hidden_dim):\n",
    "    model = Sequential()\n",
    "    for i in range(1,len(hidden_dim)-1):\n",
    "        if (i==1):\n",
    "            model.add(Dense(hidden_dim[i],input_dim=hidden_dim[0],activation=\"relu\"))\n",
    "        else:\n",
    "            model.add(Dense(hidden_dim[i],activation=\"relu\"))\n",
    "    model.add(Dense(hidden_dim[-1],kernel_initializer=\"normal\",activation=\"linear\"))\n",
    "    model.compile(loss=\"mean_squared_error\",optimizer = \"adam\",metrics = [\"mse\"])\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 3s 2ms/step - loss: 0.6886 - accuracy: 0.6233\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.7242\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.7444\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.7344\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.7141\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7438\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.7079\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7418\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.6991\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7222\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7370\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.7122\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7258\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7434\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.6974\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7250\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7576\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7125\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7216\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7404\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7564\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7503\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7559\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7663\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7478\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7281\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7545\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.7245\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7640\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7265\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7629\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7782\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7694\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7362\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7572\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7542\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7491\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7709\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7611\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7570\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7581\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7491\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7757\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7479\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7744\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7674\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7889\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7624\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7734\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7976\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7874\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7410\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7637\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7773\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7686\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7725\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7922\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7444\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7669\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7805\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7741\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7723\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7717\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7669\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7852\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7800\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7736\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7568\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7729\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7574\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7769\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.8013\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7487\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7628\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7962\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8166\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7792\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7435\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7623\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7822\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7438\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7746\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7639\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7408\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7708\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7768\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7451\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7916\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7527\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7507\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7885\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7541\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7732\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7707\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7361\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7695\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7980\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7580\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7884\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8205\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7606\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7640\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7729\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7879\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7773\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7538\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7801\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7657\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7614\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.8035\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7467\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7508\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7518\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7743\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7554\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7655\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7964\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7642\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7571\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8060\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7422\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7704\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7908\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7983\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7624\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7700\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7478\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7338\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8011\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7771\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7979\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7814\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7580\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7498\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7549\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7741\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7969\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7860\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7414\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7487\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7474\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7651\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7724\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7544\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7763\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7758\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7838\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7725\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7709\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7573\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7994\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7888\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7608\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7849\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7867\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7625\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7925\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7830\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7521\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7695\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7844\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7903\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7645\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7662\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7426\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7414\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7720\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7547\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7695\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7532\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7662\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7839\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7681\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7728\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7660\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7854\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7683\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7530\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7752\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7885\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7930\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7871\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7663\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7747\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7668\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7723\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7799\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7594\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7508\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7786\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7859\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7793\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7718\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7542\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7649\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7869\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7904\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7701\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7487\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7755\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7835\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8075\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7758\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7871\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7890\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7677\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7883\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7680\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7432\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7483\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7827\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7760\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7676\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7891\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8056\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7592\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7827\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7702\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7557\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7859\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7491\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7606\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7775\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7693\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7469\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.8022\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7786\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7560\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7703\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7589\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7571\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7820\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7873\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7511\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7573\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7602\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7537\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7617\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7944\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7963\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7574\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7444\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7868\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7515\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7996\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7597\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8044\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7825\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7628\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8073\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7418\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7588\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7832\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7860\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7751\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7556\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7852\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7843\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7502\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7904\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7806\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7578\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7369\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7706\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7755\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7799\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7794\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7855\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7599\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7752\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7683\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7667\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7763\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7894\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7635\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7692\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7532\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7801\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7787\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7826\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8084\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7797\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7635\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7832\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7664\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7670\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7936\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7619\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7712\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7567\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.71 - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7545\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7342\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.81 - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7817\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7791\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8011\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7700\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7897\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7988\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7751\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7658\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7475\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7913\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7668\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7672\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7731\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7487\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7951\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7847\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7720\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7806\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7811\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7431\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7719\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7934\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7554\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7534\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7422\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7565\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7813\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7776\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.8002\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7737\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7989\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7644\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7796\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7755\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7917\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7274\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7629\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7628\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7693\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7713\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7325\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7366\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7797\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7696\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7668\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7505\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7641\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7746\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7688\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7597\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5221 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7773\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7735\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7688\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7634\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7535\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7717\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7773\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7875\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7727\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7519\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7929\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7843\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7895\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7734\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7847\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7925\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7617\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7695\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7668\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7897\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7470\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7470\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7302\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7557\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7814\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7578\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7422\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7538\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7682\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7628\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7640\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7807\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7692\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7638\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7494\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7684\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7649\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8054\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7770\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7541\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7743\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7649\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7169\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8100\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7530\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7608\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7660\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7705\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7664\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7729\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7738\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7598\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7531\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7669\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7933\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7649\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7532\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7596\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7653\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7549\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7530\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7729\n",
      "Epoch 405/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7681\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7802\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7659\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7774\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7699\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7805\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7688\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7717\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7615\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7747\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7670\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7640\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7871\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7911\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7816\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7926\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7847\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7758\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7642\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7553\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7922\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7956\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7466\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7732\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7760\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8079\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7908\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7745\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7693\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7812\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7716\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7916\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 954us/step - loss: 0.4704 - accuracy: 0.7751\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7521\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7659\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7429\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7849\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7618\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7683\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7800\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7813\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7686\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7709\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7767\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7676\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7513\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7454\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7812\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7812\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7520\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7527\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7828\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.7576\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7502\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7778\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7818\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7858\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7349\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7668\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7780\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7768\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7883\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7504\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7705\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7480\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7843\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7775\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7690\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7784\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7783\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7844\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7699\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7713\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7808\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7541\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7654\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7585\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7764\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7645\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7583\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7973\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7716\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7793\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7719\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7604\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7943\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7656\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7581\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7909\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7805\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7794\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7766\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 936us/step - loss: 0.4310 - accuracy: 0.8075\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7841\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7663\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7718\n"
     ]
    }
   ],
   "source": [
    "#fitting the model to x train & y train\n",
    "first_model = prep_model([28,50,40,20,1])\n",
    "first_model.fit(np.asarray(x_train).astype(np.int),np.asarray(y_train).astype(np.int),epochs=500)\n",
    "pred_train = first_model.predict(np.array(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-ee55b7cabec5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(predictors,target)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'init')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-0cb595502256>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# create model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m                \u001b[0mbias_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                **kwargs):\n\u001b[1;32m-> 1143\u001b[1;33m     super(Dense, self).__init__(\n\u001b[0m\u001b[0;32m   1144\u001b[0m         activity_regularizer=activity_regularizer, **kwargs)\n\u001b[0;32m   1145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m     }\n\u001b[0;32m    322\u001b[0m     \u001b[1;31m# Validate optional keyword arguments.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m     \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;31m# Mutable properties\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[1;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[0;32m   1132\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1134\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'init')"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=28, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 241 samples, validate on 120 samples\n",
      "Epoch 1/150\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.7054 - val_loss: 0.6880 - val_accuracy: 0.7000\n",
      "Epoch 2/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.6802 - accuracy: 0.7469 - val_loss: 0.6761 - val_accuracy: 0.7000\n",
      "Epoch 3/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.6614 - accuracy: 0.7469 - val_loss: 0.6541 - val_accuracy: 0.7000\n",
      "Epoch 4/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.6239 - accuracy: 0.7469 - val_loss: 0.6229 - val_accuracy: 0.7000\n",
      "Epoch 5/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.5787 - accuracy: 0.7469 - val_loss: 0.6132 - val_accuracy: 0.7000\n",
      "Epoch 6/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.5617 - accuracy: 0.7469 - val_loss: 0.6189 - val_accuracy: 0.7000\n",
      "Epoch 7/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.5611 - accuracy: 0.7469 - val_loss: 0.6207 - val_accuracy: 0.7000\n",
      "Epoch 8/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.5584 - accuracy: 0.7469 - val_loss: 0.6219 - val_accuracy: 0.7000\n",
      "Epoch 9/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.5558 - accuracy: 0.7469 - val_loss: 0.6252 - val_accuracy: 0.7000\n",
      "Epoch 10/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.5540 - accuracy: 0.7469 - val_loss: 0.6271 - val_accuracy: 0.7000\n",
      "Epoch 11/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.5529 - accuracy: 0.7469 - val_loss: 0.6235 - val_accuracy: 0.7000\n",
      "Epoch 12/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.5503 - accuracy: 0.7469 - val_loss: 0.6204 - val_accuracy: 0.7000\n",
      "Epoch 13/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.5493 - accuracy: 0.7469 - val_loss: 0.6221 - val_accuracy: 0.7000\n",
      "Epoch 14/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.5476 - accuracy: 0.7469 - val_loss: 0.6277 - val_accuracy: 0.7000\n",
      "Epoch 15/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.5453 - accuracy: 0.7469 - val_loss: 0.6261 - val_accuracy: 0.7000\n",
      "Epoch 16/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.5430 - accuracy: 0.7469 - val_loss: 0.6267 - val_accuracy: 0.7000\n",
      "Epoch 17/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.5410 - accuracy: 0.7469 - val_loss: 0.6293 - val_accuracy: 0.7000\n",
      "Epoch 18/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.5393 - accuracy: 0.7469 - val_loss: 0.6290 - val_accuracy: 0.7000\n",
      "Epoch 19/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.5370 - accuracy: 0.7469 - val_loss: 0.6298 - val_accuracy: 0.7000\n",
      "Epoch 20/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.5350 - accuracy: 0.7469 - val_loss: 0.6310 - val_accuracy: 0.7000\n",
      "Epoch 21/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.5335 - accuracy: 0.7469 - val_loss: 0.6337 - val_accuracy: 0.7000\n",
      "Epoch 22/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.5314 - accuracy: 0.7469 - val_loss: 0.6308 - val_accuracy: 0.7000\n",
      "Epoch 23/150\n",
      "241/241 [==============================] - 0s 299us/step - loss: 0.5283 - accuracy: 0.7469 - val_loss: 0.6341 - val_accuracy: 0.7000\n",
      "Epoch 24/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.5258 - accuracy: 0.7469 - val_loss: 0.6373 - val_accuracy: 0.7000\n",
      "Epoch 25/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.5257 - accuracy: 0.7469 - val_loss: 0.6398 - val_accuracy: 0.7000\n",
      "Epoch 26/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.5233 - accuracy: 0.7469 - val_loss: 0.6397 - val_accuracy: 0.7000\n",
      "Epoch 27/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.5213 - accuracy: 0.7469 - val_loss: 0.6405 - val_accuracy: 0.7000\n",
      "Epoch 28/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.5193 - accuracy: 0.7469 - val_loss: 0.6427 - val_accuracy: 0.7000\n",
      "Epoch 29/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.5180 - accuracy: 0.7469 - val_loss: 0.6435 - val_accuracy: 0.7000\n",
      "Epoch 30/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.5167 - accuracy: 0.7469 - val_loss: 0.6444 - val_accuracy: 0.7000\n",
      "Epoch 31/150\n",
      "241/241 [==============================] - 0s 166us/step - loss: 0.5150 - accuracy: 0.7510 - val_loss: 0.6445 - val_accuracy: 0.7000\n",
      "Epoch 32/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.5132 - accuracy: 0.7510 - val_loss: 0.6489 - val_accuracy: 0.7083\n",
      "Epoch 33/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.5123 - accuracy: 0.7676 - val_loss: 0.6511 - val_accuracy: 0.6917\n",
      "Epoch 34/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.5122 - accuracy: 0.7552 - val_loss: 0.6561 - val_accuracy: 0.6917\n",
      "Epoch 35/150\n",
      "241/241 [==============================] - 0s 299us/step - loss: 0.5105 - accuracy: 0.7635 - val_loss: 0.6516 - val_accuracy: 0.7083\n",
      "Epoch 36/150\n",
      "241/241 [==============================] - 0s 332us/step - loss: 0.5099 - accuracy: 0.7759 - val_loss: 0.6533 - val_accuracy: 0.7083\n",
      "Epoch 37/150\n",
      "241/241 [==============================] - 0s 332us/step - loss: 0.5086 - accuracy: 0.7801 - val_loss: 0.6518 - val_accuracy: 0.7083\n",
      "Epoch 38/150\n",
      "241/241 [==============================] - 0s 332us/step - loss: 0.5071 - accuracy: 0.7759 - val_loss: 0.6570 - val_accuracy: 0.7083\n",
      "Epoch 39/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.5060 - accuracy: 0.7801 - val_loss: 0.6579 - val_accuracy: 0.7083\n",
      "Epoch 40/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.5051 - accuracy: 0.7759 - val_loss: 0.6602 - val_accuracy: 0.7083\n",
      "Epoch 41/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.5033 - accuracy: 0.7801 - val_loss: 0.6602 - val_accuracy: 0.7083\n",
      "Epoch 42/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.5028 - accuracy: 0.7801 - val_loss: 0.6597 - val_accuracy: 0.7083\n",
      "Epoch 43/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.5030 - accuracy: 0.7801 - val_loss: 0.6575 - val_accuracy: 0.7083\n",
      "Epoch 44/150\n",
      "241/241 [==============================] - 0s 166us/step - loss: 0.5010 - accuracy: 0.7759 - val_loss: 0.6649 - val_accuracy: 0.7083\n",
      "Epoch 45/150\n",
      "241/241 [==============================] - 0s 166us/step - loss: 0.4982 - accuracy: 0.7801 - val_loss: 0.6639 - val_accuracy: 0.7083\n",
      "Epoch 46/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4974 - accuracy: 0.7801 - val_loss: 0.6673 - val_accuracy: 0.7083\n",
      "Epoch 47/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4966 - accuracy: 0.7801 - val_loss: 0.6669 - val_accuracy: 0.7083\n",
      "Epoch 48/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4953 - accuracy: 0.7801 - val_loss: 0.6659 - val_accuracy: 0.7083\n",
      "Epoch 49/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4946 - accuracy: 0.7801 - val_loss: 0.6693 - val_accuracy: 0.7083\n",
      "Epoch 50/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4936 - accuracy: 0.7801 - val_loss: 0.6689 - val_accuracy: 0.7083\n",
      "Epoch 51/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4925 - accuracy: 0.7801 - val_loss: 0.6712 - val_accuracy: 0.7083\n",
      "Epoch 52/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4903 - accuracy: 0.7842 - val_loss: 0.6687 - val_accuracy: 0.7083\n",
      "Epoch 53/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4933 - accuracy: 0.7801 - val_loss: 0.6684 - val_accuracy: 0.7083\n",
      "Epoch 54/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4884 - accuracy: 0.7925 - val_loss: 0.6667 - val_accuracy: 0.6917\n",
      "Epoch 55/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4875 - accuracy: 0.7967 - val_loss: 0.6648 - val_accuracy: 0.7000\n",
      "Epoch 56/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4891 - accuracy: 0.8091 - val_loss: 0.6684 - val_accuracy: 0.7000\n",
      "Epoch 57/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4836 - accuracy: 0.7925 - val_loss: 0.6751 - val_accuracy: 0.7083\n",
      "Epoch 58/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4855 - accuracy: 0.7925 - val_loss: 0.6698 - val_accuracy: 0.7000\n",
      "Epoch 59/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4837 - accuracy: 0.8008 - val_loss: 0.6740 - val_accuracy: 0.7000\n",
      "Epoch 60/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4826 - accuracy: 0.7925 - val_loss: 0.6757 - val_accuracy: 0.7000\n",
      "Epoch 61/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4803 - accuracy: 0.7925 - val_loss: 0.6758 - val_accuracy: 0.7000\n",
      "Epoch 62/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4804 - accuracy: 0.8008 - val_loss: 0.6754 - val_accuracy: 0.7000\n",
      "Epoch 63/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4772 - accuracy: 0.8091 - val_loss: 0.6768 - val_accuracy: 0.7000\n",
      "Epoch 64/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4764 - accuracy: 0.8008 - val_loss: 0.6809 - val_accuracy: 0.7000\n",
      "Epoch 65/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4753 - accuracy: 0.8008 - val_loss: 0.6782 - val_accuracy: 0.7000\n",
      "Epoch 66/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4736 - accuracy: 0.8050 - val_loss: 0.6808 - val_accuracy: 0.7000\n",
      "Epoch 67/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4723 - accuracy: 0.8091 - val_loss: 0.6781 - val_accuracy: 0.7000\n",
      "Epoch 68/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4717 - accuracy: 0.8050 - val_loss: 0.6838 - val_accuracy: 0.7000\n",
      "Epoch 69/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4703 - accuracy: 0.8050 - val_loss: 0.6825 - val_accuracy: 0.7000\n",
      "Epoch 70/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4685 - accuracy: 0.8008 - val_loss: 0.6796 - val_accuracy: 0.7000\n",
      "Epoch 71/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4694 - accuracy: 0.8050 - val_loss: 0.6779 - val_accuracy: 0.7083\n",
      "Epoch 72/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4687 - accuracy: 0.8091 - val_loss: 0.6834 - val_accuracy: 0.7000\n",
      "Epoch 73/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4654 - accuracy: 0.8050 - val_loss: 0.6820 - val_accuracy: 0.7000\n",
      "Epoch 74/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4665 - accuracy: 0.8091 - val_loss: 0.6859 - val_accuracy: 0.7000\n",
      "Epoch 75/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4639 - accuracy: 0.8050 - val_loss: 0.6859 - val_accuracy: 0.7000\n",
      "Epoch 76/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4642 - accuracy: 0.8050 - val_loss: 0.6867 - val_accuracy: 0.7000\n",
      "Epoch 77/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4618 - accuracy: 0.8050 - val_loss: 0.6785 - val_accuracy: 0.7167\n",
      "Epoch 78/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4592 - accuracy: 0.8050 - val_loss: 0.6874 - val_accuracy: 0.7000\n",
      "Epoch 79/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4634 - accuracy: 0.8050 - val_loss: 0.6870 - val_accuracy: 0.7083\n",
      "Epoch 80/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4574 - accuracy: 0.8050 - val_loss: 0.6873 - val_accuracy: 0.7083\n",
      "Epoch 81/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4586 - accuracy: 0.8091 - val_loss: 0.6864 - val_accuracy: 0.7167\n",
      "Epoch 82/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4562 - accuracy: 0.8050 - val_loss: 0.6850 - val_accuracy: 0.7083\n",
      "Epoch 83/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4555 - accuracy: 0.8050 - val_loss: 0.6904 - val_accuracy: 0.7083\n",
      "Epoch 84/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4559 - accuracy: 0.8091 - val_loss: 0.6712 - val_accuracy: 0.7167\n",
      "Epoch 85/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4543 - accuracy: 0.8050 - val_loss: 0.6804 - val_accuracy: 0.7083\n",
      "Epoch 86/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4528 - accuracy: 0.8091 - val_loss: 0.6817 - val_accuracy: 0.7083\n",
      "Epoch 87/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4502 - accuracy: 0.8050 - val_loss: 0.6832 - val_accuracy: 0.7083\n",
      "Epoch 88/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4497 - accuracy: 0.8050 - val_loss: 0.6826 - val_accuracy: 0.7083\n",
      "Epoch 89/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4469 - accuracy: 0.8091 - val_loss: 0.6828 - val_accuracy: 0.7083\n",
      "Epoch 90/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4484 - accuracy: 0.8091 - val_loss: 0.6740 - val_accuracy: 0.7167\n",
      "Epoch 91/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4450 - accuracy: 0.8050 - val_loss: 0.6796 - val_accuracy: 0.7083\n",
      "Epoch 92/150\n",
      "241/241 [==============================] - 0s 299us/step - loss: 0.4448 - accuracy: 0.8050 - val_loss: 0.6835 - val_accuracy: 0.7167\n",
      "Epoch 93/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4429 - accuracy: 0.8050 - val_loss: 0.6839 - val_accuracy: 0.7167\n",
      "Epoch 94/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4532 - accuracy: 0.8216 - val_loss: 0.6791 - val_accuracy: 0.7167\n",
      "Epoch 95/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4437 - accuracy: 0.8050 - val_loss: 0.6885 - val_accuracy: 0.7083\n",
      "Epoch 96/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4390 - accuracy: 0.8133 - val_loss: 0.6825 - val_accuracy: 0.7167\n",
      "Epoch 97/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.4373 - accuracy: 0.8133 - val_loss: 0.6838 - val_accuracy: 0.7167\n",
      "Epoch 98/150\n",
      "241/241 [==============================] - 0s 166us/step - loss: 0.4355 - accuracy: 0.8091 - val_loss: 0.6884 - val_accuracy: 0.7167\n",
      "Epoch 99/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4391 - accuracy: 0.8091 - val_loss: 0.6900 - val_accuracy: 0.7167\n",
      "Epoch 100/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4336 - accuracy: 0.8133 - val_loss: 0.6829 - val_accuracy: 0.7167\n",
      "Epoch 101/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4323 - accuracy: 0.8091 - val_loss: 0.6796 - val_accuracy: 0.7167\n",
      "Epoch 102/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4344 - accuracy: 0.8133 - val_loss: 0.6875 - val_accuracy: 0.7167\n",
      "Epoch 103/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4297 - accuracy: 0.8091 - val_loss: 0.6977 - val_accuracy: 0.7167\n",
      "Epoch 104/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4328 - accuracy: 0.8050 - val_loss: 0.6943 - val_accuracy: 0.7167\n",
      "Epoch 105/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4262 - accuracy: 0.8091 - val_loss: 0.6875 - val_accuracy: 0.7167\n",
      "Epoch 106/150\n",
      "241/241 [==============================] - 0s 266us/step - loss: 0.4263 - accuracy: 0.8091 - val_loss: 0.6920 - val_accuracy: 0.7167\n",
      "Epoch 107/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4269 - accuracy: 0.8091 - val_loss: 0.6865 - val_accuracy: 0.7250\n",
      "Epoch 108/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4234 - accuracy: 0.8050 - val_loss: 0.6916 - val_accuracy: 0.7167\n",
      "Epoch 109/150\n",
      "241/241 [==============================] - 0s 266us/step - loss: 0.4243 - accuracy: 0.8133 - val_loss: 0.6942 - val_accuracy: 0.7167\n",
      "Epoch 110/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4272 - accuracy: 0.8340 - val_loss: 0.6774 - val_accuracy: 0.7250\n",
      "Epoch 111/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4239 - accuracy: 0.8091 - val_loss: 0.6859 - val_accuracy: 0.7167\n",
      "Epoch 112/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4188 - accuracy: 0.8133 - val_loss: 0.6849 - val_accuracy: 0.7167\n",
      "Epoch 113/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4219 - accuracy: 0.8174 - val_loss: 0.6791 - val_accuracy: 0.7250\n",
      "Epoch 114/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4162 - accuracy: 0.8133 - val_loss: 0.6875 - val_accuracy: 0.7167\n",
      "Epoch 115/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4145 - accuracy: 0.8133 - val_loss: 0.6862 - val_accuracy: 0.7250\n",
      "Epoch 116/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4121 - accuracy: 0.8091 - val_loss: 0.6890 - val_accuracy: 0.7250\n",
      "Epoch 117/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4127 - accuracy: 0.8091 - val_loss: 0.6904 - val_accuracy: 0.7250\n",
      "Epoch 118/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4103 - accuracy: 0.8091 - val_loss: 0.6891 - val_accuracy: 0.7250\n",
      "Epoch 119/150\n",
      "241/241 [==============================] - 0s 299us/step - loss: 0.4105 - accuracy: 0.8133 - val_loss: 0.6925 - val_accuracy: 0.7250\n",
      "Epoch 120/150\n",
      "241/241 [==============================] - 0s 299us/step - loss: 0.4098 - accuracy: 0.8091 - val_loss: 0.6904 - val_accuracy: 0.7167\n",
      "Epoch 121/150\n",
      "241/241 [==============================] - 0s 299us/step - loss: 0.4085 - accuracy: 0.8133 - val_loss: 0.6889 - val_accuracy: 0.7333\n",
      "Epoch 122/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.4047 - accuracy: 0.8091 - val_loss: 0.6902 - val_accuracy: 0.7167\n",
      "Epoch 123/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4057 - accuracy: 0.8091 - val_loss: 0.6899 - val_accuracy: 0.7333\n",
      "Epoch 124/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4011 - accuracy: 0.8216 - val_loss: 0.6922 - val_accuracy: 0.7250\n",
      "Epoch 125/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4012 - accuracy: 0.8174 - val_loss: 0.6928 - val_accuracy: 0.7250\n",
      "Epoch 126/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3986 - accuracy: 0.8216 - val_loss: 0.6886 - val_accuracy: 0.7333\n",
      "Epoch 127/150\n",
      "241/241 [==============================] - 0s 265us/step - loss: 0.3989 - accuracy: 0.8340 - val_loss: 0.6906 - val_accuracy: 0.7333\n",
      "Epoch 128/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3964 - accuracy: 0.8174 - val_loss: 0.6902 - val_accuracy: 0.7333\n",
      "Epoch 129/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.4039 - accuracy: 0.8299 - val_loss: 0.6937 - val_accuracy: 0.7333\n",
      "Epoch 130/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.3915 - accuracy: 0.8216 - val_loss: 0.6973 - val_accuracy: 0.7333\n",
      "Epoch 131/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3962 - accuracy: 0.8133 - val_loss: 0.6909 - val_accuracy: 0.7333\n",
      "Epoch 132/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.3970 - accuracy: 0.8174 - val_loss: 0.6918 - val_accuracy: 0.7333\n",
      "Epoch 133/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.3908 - accuracy: 0.8216 - val_loss: 0.6892 - val_accuracy: 0.7333\n",
      "Epoch 134/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.3867 - accuracy: 0.8216 - val_loss: 0.6947 - val_accuracy: 0.7333\n",
      "Epoch 135/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.3877 - accuracy: 0.8299 - val_loss: 0.6913 - val_accuracy: 0.7333\n",
      "Epoch 136/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.3869 - accuracy: 0.8299 - val_loss: 0.6865 - val_accuracy: 0.7333\n",
      "Epoch 137/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3914 - accuracy: 0.8133 - val_loss: 0.6972 - val_accuracy: 0.7250\n",
      "Epoch 138/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3807 - accuracy: 0.8257 - val_loss: 0.6886 - val_accuracy: 0.7333\n",
      "Epoch 139/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3787 - accuracy: 0.8257 - val_loss: 0.6885 - val_accuracy: 0.7333\n",
      "Epoch 140/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.3780 - accuracy: 0.8257 - val_loss: 0.6872 - val_accuracy: 0.7333\n",
      "Epoch 141/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3869 - accuracy: 0.8091 - val_loss: 0.6831 - val_accuracy: 0.7333\n",
      "Epoch 142/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3778 - accuracy: 0.8216 - val_loss: 0.6778 - val_accuracy: 0.7333\n",
      "Epoch 143/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3745 - accuracy: 0.8257 - val_loss: 0.6758 - val_accuracy: 0.7333\n",
      "Epoch 144/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3740 - accuracy: 0.8174 - val_loss: 0.6760 - val_accuracy: 0.7333\n",
      "Epoch 145/150\n",
      "241/241 [==============================] - 0s 232us/step - loss: 0.3721 - accuracy: 0.8299 - val_loss: 0.6805 - val_accuracy: 0.7333\n",
      "Epoch 146/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3737 - accuracy: 0.8423 - val_loss: 0.6830 - val_accuracy: 0.7333\n",
      "Epoch 147/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3754 - accuracy: 0.8382 - val_loss: 0.6794 - val_accuracy: 0.7333\n",
      "Epoch 148/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3676 - accuracy: 0.8340 - val_loss: 0.6899 - val_accuracy: 0.7333\n",
      "Epoch 149/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3721 - accuracy: 0.8216 - val_loss: 0.6824 - val_accuracy: 0.7333\n",
      "Epoch 150/150\n",
      "241/241 [==============================] - 0s 199us/step - loss: 0.3623 - accuracy: 0.8257 - val_loss: 0.6755 - val_accuracy: 0.7333\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "hist=model.fit(np.array(x_train),np.array(y_train), validation_split=0.33, nb_epoch=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 22us/step\n",
      "accuracy: 79.78%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(x_train,y_train)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Thus we are getting the best acurracy using loss=\"binary_crossentropy\",optimizer = \"rmsprop\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize training history\n",
    "\n",
    "# list all data in history\n",
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
